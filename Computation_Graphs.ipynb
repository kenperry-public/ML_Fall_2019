{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Computation graphs\n",
    "\n",
    "## Intuitive explanation\n",
    "\n",
    "When you first look at TensorFlow code, it looks like your familiar imperative program:\n",
    "- familiar operators\n",
    "    - assignment, addition, multiplication\n",
    "    - may overload operators `=`, `+`, `*`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is some familiar Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 1\n",
    "c = a + b\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and the very similar looking TensorFlow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "a = tf.Variable(2)\n",
    "b = tf.Variable(1)\n",
    "c= tf.add(a,b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In fact we could have written\n",
    "\n",
    "`c = tf.add(a,b)`\n",
    "\n",
    "as\n",
    "\n",
    "` c = a + b`\n",
    "\n",
    "in order to make Tensorflow look more like Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is **not** the same.\n",
    "\n",
    "Tensorflow distinguishes between\n",
    "- program declaration/definition\n",
    "- program evaluation/execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Program declaration**\n",
    "\n",
    "Although the code  *looks* just like ordinary Python, the statements are *defining* a computation,\n",
    "not demanding that the statements be executed immediately.\n",
    "\n",
    "**Program evaluation**\n",
    "\n",
    "You must take  *explicit* steps to execute the program, after passing in initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The statements in TensorFlow are not executed immediately (as in an imperative program)\n",
    "    - they are defining a future computation (the \"computation graph\")\n",
    "    - think of it a defining the *body* of a function\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In order to evaluate (i.e., \"call\") the function ('computation graphs\")\n",
    "    - You must create a \"session\" in TensorFlow\n",
    "    - All code must be run within a session\n",
    "    - The code is evaluated by explicitly asking for something to be \"evaluated\" or \"run\"\n",
    "        - When evaluating/running: you must pass in actual values for the formal parameters (function arguments/place holders)\n",
    "We've swept some subtle but important details under the rug.\n",
    "\n",
    "\n",
    "Consider the imperative Python program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Raw Tensorflow Notebook from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2019/blob/master/Raw_TensorFlow.ipynb)\n",
    "\n",
    "[DNN Tensorflow example Notebook from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2019/blob/master/DNN_TensorFlow_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Think of the above Tensorflow code as defining a function (we'll call it foo)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def foo():\n",
    "    a = 2\n",
    "    b = 1\n",
    "    c= a + b\n",
    "    \n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The above was *program definition. \n",
    "\n",
    "As for evaluation of the program: you must explicitly request it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can make the distinction between definition and evaluation even more sharply by\n",
    "changing one local variable to a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def foo1(a):\n",
    "    b = 1\n",
    "    c= a + b\n",
    "    \n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "foo1(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is: the definition of `foo1` is partial.\n",
    "    \n",
    "There is an unbound variable `a` that must be provided at evaluation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This simple analogy is only partially accurate.\n",
    "\n",
    "In spite of the fact that `a` is an unbound variable, I can assert\n",
    "that\n",
    "- the value of `c` is the sum of the values of `a` and `b`, regardless of what those values are\n",
    "\n",
    "So it is not entirely unreasonable (if you had never seen Python before) to have expected that\n",
    "\n",
    "`print(c)`\n",
    "\n",
    "would have returned the string `a + b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is: you can view the program definition as specifying a *manipulation of symbols* (algebra)\n",
    "- rather than a manipulation of *values*\n",
    "    - which has a prerequisite of binding values to every symbol\n",
    "- the manipulation of symbols holds even though I may not yet know the value of any symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the Tensorflow program above will print\n",
    "\n",
    "`Tensor(\"Add_1:0\", shape=(), dtype=int32)`\n",
    "\n",
    "which is Tensorflow's way as saying that `c` involves addition\n",
    "- further inspection would show that the two addends are `a` and `b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tensorflow program definition is specifying a *symbolic computation*\n",
    "- I can *describe* the symbol manipulation that each statement is specifying\n",
    "- This description can be made even before we have bound a value to any symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take this one step further: suppose `a` was the product of two other symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "a = tf.mult(d, e)\n",
    "b = tf.Variable(1)\n",
    "c= tf.add(a,b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then `print(c)` will still give the same result\n",
    "- but the inspection of `a`\n",
    "    - will reveal that Tensorflow will apply a multiplication\n",
    "    - with multiplicands `d` and `e`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tensorflow is literally building a graph of information flow\n",
    "\n",
    "To actually do something, you have to \"evaluate\" part of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  init.run()\n",
    " \n",
    "  c_value = sess.run(c)\n",
    "  print(\"c value:\", c_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the imperative program (Python), each line is evaluated immediately after it is executed.\n",
    "\n",
    "In the declarative program (Tensorflow), it is not evaluated: \n",
    "- it just creates a dependence between outputs (c) and inputs (a and b). \n",
    "- When you evaluate c, it recursively evaluates all the things that c depends on.\n",
    "\n",
    "Hence, you are declaring a graph that is evaluated later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computation graph: a node is an expression, not a value\n",
    "\n",
    "Imagine that a variable has two attributes\n",
    "- `c.value`: the current \"value\" of the variable\n",
    "- `c.expr` - the expression that computes `c`\n",
    "\n",
    "When we write\n",
    ">`c = a + b`\n",
    "\n",
    "in our familiar imperative programming languages, this really denotes the imperative\n",
    ">`c.value = a.value + b.value`\n",
    "\n",
    "That is, the string `c = a + b` is a *command* to modify the value of `c`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a declarative program, the string `c = a + b` defines a *function* that computes `c` from two\n",
    "inputs `a, b`\n",
    "\n",
    ">`c.expr = lambda a,b: plus(a,b)`\n",
    "\n",
    "Thus, it's possible to write the string `c = a + b` even before `a, b` have been initialized\n",
    "because `a, b` are just formal parameters to the function `c.expr`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to *evaluate* `c.expr` (i.e., compute the concrete value `c.value`) we must first evaluate\n",
    "\n",
    ">`a.expr, b.expr`\n",
    "\n",
    "Note that the declarative program distinguishes between *declaring/defining* an expression\n",
    "and *evaluating* it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More formally, the `eval` operator (which derives a value from a function) applied to `c` results in\n",
    "\n",
    ">`eval(c.expr) = plus( eval(a.expr), eval(b.expr) )`\n",
    "\n",
    "These in turn might be expressions that depend on other expressions, e.g., \n",
    ">`a.expr = lambda d, e: mult(d,e)`\n",
    "\n",
    "So the evaluation of the top-level expression `c.expr` involves recursively evaluating all\n",
    "expressions on which `c.expr` depends.\n",
    "Eventually the recursion unwinds to a base case in which the expression involves no further computation\n",
    "\n",
    ">`d = lambda: d.value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As we traverse the code of the declarative program, we are defining more and more functions,\n",
    "and dependencies between functions (i.e., some functions consume the results of other functions as arguments).\n",
    "\n",
    "This collection of functions is called a *computation tree*.\n",
    "A computation tree is just a collection of functions and dependencies.\n",
    "A node `c` in the tree has *no concrete* value until we request it to be *evaluated*, which\n",
    "involves \n",
    "- binding concrete values to all leaf nodes of the sub-tree defining `c.expr`\n",
    "- recursively evaluating the nodes on which `c` depends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eager execution\n",
    "\n",
    "Many people find declarative programming confusing (and perhaps pointless).\n",
    "\n",
    "As you will see, there is a point (and a very big one. Hint: do you like to write derivatives ?)\n",
    "\n",
    "TF supports \"eager execution\" which makes TF look like an imperative language. This is optional in TF v1, and standard in TF v2.\n",
    "\n",
    "So, when reading other people's code, it's important to observe whether eager execution has been enabled.\n",
    "\n",
    "TF v2 is not yet standard so most code you will currently see is declarative.\n",
    "\n",
    "You may stumble at first, but it is very powerful.\n",
    "\n",
    "[Introducing Eager execution](https://developers.googleblog.com/2017/10/eager-execution-imperative-define-by.html?source=post_page---------------------------)\n",
    "- Because you are not building a graph, the training loop is different\n",
    "    - more Pythonic\n",
    "    - no need to\n",
    "        - instantiate session\n",
    "        - `eval` or `run` the training step\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "for (x, y) in tfe.Iterator(dataset):\n",
    "  grads = tfe.implicit_gradients(loss_function)(model, x, y)\n",
    "  optimizer.apply_gradients(grads)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
