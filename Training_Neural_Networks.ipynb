{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{\\tp}{\\mathbf{{(t)}}}\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro `_latex_std_` created. To execute, type its name (without quotes).\n",
      "=== Macro contents: ===\n",
      "get_ipython().run_line_magic('run', 'Latex_macros.ipynb')\n",
      " "
     ]
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neural_net_helper\n",
    "%aimport neural_net_helper\n",
    "\n",
    "nnh = neural_net_helper.NN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notation\n",
    "Layer $\\ll$:\n",
    "\n",
    "- output of layer $\\ll: \\y_\\llp$\n",
    "- input of layer $\\ll: \\y_{(\\ll-1)}$\n",
    "- layer $0$ (*the input layer*) \n",
    "    - $\\y_{(0)} = \\x$\n",
    "- layer $L$ (output layer)\n",
    "    - $\\hat{y} = \\y = \\y_{(L)}$    \n",
    "- layer $(L+1)$ (*\"Loss layer\"*)\n",
    "    - $\\y_{(L+1)} = \\loss $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>Layers</center>\n",
    "    <br>\n",
    "<img src=images/NN_Layers.jpg width=2500>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given many choices for a layer's activation function and its computation\n",
    "we will write the input/output relation of layer $\\ll$ as\n",
    "$$\n",
    "\\y_{(\\ll)} = a_{(\\ll)}( f_{(\\ll)}( \\y_{(\\ll-1)}, \\W_{(\\ll)}) )\n",
    "$$\n",
    "\n",
    "for\n",
    "- activation function $a_\\llp$\n",
    "- weights $\\W_\\llp$\n",
    "- $\\y_{(\\ll-1)}$ are the outputs of the previous layer\n",
    "\n",
    "- $f_{(\\ll)}$ is the function computed by layer $\\ll$\n",
    "    - function of input $\\y_{(\\ll-1)}$ and weights $\\W_\\llp$\n",
    "    - e.g., `Dense`: $f_{(\\ll)}( \\y_{(\\ll-1)}, \\W_{(\\ll)}) = \\y_\\llp = \\W_\\llp \\y_{(\\ll-1)} + \\b_\\llp$\n",
    "\n",
    "**Note** We neglect to add $\\b_\\llp$ as an argument to $f_\\llp$ to simplify notation\n",
    "- as a convenience we sometimes view $\\b_\\llp$ as being part of $\\W_\\llp$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>Layers</center>\n",
    "    <br>\n",
    "<img src=images/NN_Layers_1.jpg width=600>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Back propagation\n",
    "\n",
    "Gradient Decent works by updating weights $\\W_\\llp$ by the derivative of the loss $\\loss$ with respect to $\\W_\\llp$.\n",
    "\n",
    "We will now show how the derivatives \n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\frac{\\partial \\loss}{\\partial \\W_\\llp} \\,\\text{for} \\; \\ll=1, \\ldots, L\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "are computed, first mathematically and then by code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can do this via a procedure know as back propagation\n",
    "\n",
    "It is really nothing more than an *iterated* application of the Chain Rule of Calculus.\n",
    "\n",
    "Let \n",
    "- $\\loss$ denote loss (computed after final layer $L$)\n",
    "- $\\loss'_\\llp = \\frac{\\partial \\loss}{\\partial y_\\llp}$ denote the derivative of $\\loss$ with respect to the output of layer $\\ll$, i.e., $y_\\llp$,\n",
    "    - refer to as **loss gradient** (at output of layer $\\ll$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will show how to compute \n",
    "- $\\frac{\\partial \\loss}{\\partial W_\\llp}$, from $\\loss'_\\llp$  for $\\ll \\in [1,L]$\n",
    "\n",
    "We will also show how to compute\n",
    "- $\\loss'_{(\\ll-1)}$ from $\\loss'_\\ll$ \n",
    "    - so that we can continue this process as the previous layer (i.e, *propogate loss gradient backwards*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that $\\y_\\llp$ is a function of $\\y_{(\\ll-1)}$ (the output of the previous layer) and $\\W_\\llp$, the parameters of layer $\\ll$.\n",
    "\n",
    "We can compute derivatives of $\\y_\\llp$ with respect to each of its inputs\n",
    "- $\\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}}$\n",
    "- $\\frac{\\partial \\y_\\llp}{\\partial \\W_\\llp}$\n",
    "\n",
    "Refer to these as **local gradients**\n",
    "\n",
    "Note that we can compute the local gradients during the **forward pass** as the derivatives only depend on inputs and not on any value subsequent to layer $\\ll$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall we defined the loss as being pseudo layer $L+1$\n",
    "$$\\y_{(L+1)} = \\loss\n",
    "$$\n",
    "\n",
    "Then $\\loss'_{(L+1)} = 1$ and this is the base for our backwards computation of $\\loss'_{\\llp}, \\ll < L+1$.\n",
    "\n",
    "Similarly we consider the input $\\x$ to be the \"output\" of layer $0$: $\\y_{(0)} = \\x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use the chain rule to obtain the \n",
    "- gradient with respect to weights $\\W_\\llp$, given the loss gradient $\\loss'_\\llp$ \n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\frac{\\partial \\loss}{\\partial \\W_\\llp} & = & \\frac{\\partial \\loss}{\\partial \\y_\\llp} \\frac{\\partial \\y_\\llp}{\\partial \\W_\\llp} & = & \\loss'_\\llp \\frac{\\partial \\y_\\llp}{\\partial \\W_\\llp}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is: \n",
    "- gradient of $\\loss$ with respect to weight $\\W_\\llp$ \n",
    "- is the loss gradient (at current step), multiplied by\n",
    "- a local gradient (with respect to input  $W_\\llp$ )\n",
    "\n",
    "So we have the information required to update $\\W_\\llp$ by Gradient Descent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now that we have gradients for layer $\\ll$, we need to work backward to layer $\\ll -1$.\n",
    "\n",
    "For the loss gradient:\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\loss'_{(\\ll-1)} & = & \\frac{\\partial \\loss}{\\partial \\y_{(\\ll-1)}} \\\\\n",
    "         & = & \\frac{\\partial \\loss}{\\partial \\y_\\llp} \\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}} \\\\\n",
    "         & = & \\loss'_\\llp \\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is, the loss gradient of the preceding layer is the product of\n",
    "- the loss gradient of the current layer\n",
    "- the local gradient with respect to the layer's inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This \"backwards\" computation may seem odd.\n",
    "\n",
    "After all, when we encounter layer $\\ll$ on the forward pass we have **no idea**\n",
    "- what the subsequent layers look like\n",
    "- what the loss (which depends on $\\y_{(L)}$) will be\n",
    "\n",
    "\n",
    "None the less:\n",
    "- all you need to know is we compute $\\loss'_\\llp$ from deep $\\ll$ to shallow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vanishing/exploding gradients\n",
    "\n",
    "Now that we have a better view of how backward propagation of gradients work, we are equipped\n",
    "to understand the difficulties of training the weights.\n",
    "\n",
    "Until the problems were understood, and solutions found, the evolution of Deep Learning\n",
    "was extremely slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's summarize back propagation up until this point\n",
    "- We compute the loss gradient $\\loss'_\\llp = \\frac{\\partial \\loss}{\\partial \\y_\\llp}$ of each layer $\\ll$ in descending order\n",
    "\n",
    "- The backward step  to compute the loss gradient of the preceding layer is:  \n",
    "    - $\\loss'_{(\\ll-1)} =  \\loss'_\\llp \\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}}$\n",
    "\n",
    "When we derived back propagation, we didn't look \"inside\" of the \"local gradient \" $\\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}}$\n",
    "\n",
    "We will do so now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's look more deeply into the  term $\\frac{\\partial \\y_\\llp}{\\partial \\y_{(i-1)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}[lllll] \\\\\n",
    "\\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}} & = & \\frac{\\partial a_\\llp ( f_\\llp(\\y_{(\\ll-1)}, \\W_\\llp))}{\\partial \\y_{(\\ll-1)}} & (\\text{def. of } \\y_\\llp) \\\\\n",
    "                                      & = & \\frac{\\partial a_\\llp ( f_\\llp(\\y_{(\\ll-1)}, W_\\llp) )}{\\partial f_\\llp(\\y_{(\\ll-1)}, \\W_\\llp)} \\frac{\\partial f_\\llp(\\y_{(\\ll-1)}, \\W_\\llp)}{\\partial \\y_{(\\ll-1)}} &  (\\text{chain rule}) \\\\\n",
    "                                      & = a'_\\llp f'_\\llp\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where we define\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "a'_\\llp & = & \\frac{\\partial a_\\llp ( f_\\llp(\\y_{(\\ll-1)}, \\W_\\llp) )}{\\partial f_\\llp(\\y_{(\\ll-1)}, \\W_\\llp)} \\\\\n",
    "f'_\\llp & = & \\frac{\\partial f_\\llp(\\y_{(\\ll-1)}, W_\\llp)}{\\partial \\y_{(\\ll-1)}} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$a'_\\llp$ is the derivative of activation function $a_\\llp$.\n",
    "\n",
    "We won't expicitly write it out other than to observe $a'_\\llp \\in [0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Substituting the value of the loss gradient into the backward update rule:\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll]\\\\\n",
    "\\loss'_{(\\ll-1)} & = &  \\loss'_\\llp \\frac{\\partial \\y_\\llp}{\\partial \\y_{(\\ll-1)}} \\\\\n",
    "         & = &  \\loss'_\\llp a'_\\llp f'_\\llp\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Hopefuly, you can see that if iterate through single backward steps, we can derive\n",
    "an expression for the loss gradient at layer $\\ll$ in terms of the loss gradient\n",
    "of the final layer $K$:\n",
    "\n",
    "Since\n",
    "$$\\loss'_\\llp  =   \\loss'_{(\\ll+1)} \\frac{\\partial \\y_{(\\ll+1)}}{\\partial \\y_\\llp}$$\n",
    "\n",
    "we get\n",
    "$$\\loss'_\\llp  =   \\loss'_{(L+1)} \\prod_{l'=i+1}^L  a'_{(l')} f'_{(l')}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The issue is that, since \n",
    "$$\n",
    "0 \\le a'_\\llp \\le \\max{z} a'_\\llp(z)\n",
    "$$\n",
    "\n",
    "the product \n",
    "$$\\prod_{l'=i+1}^K {a'_{(l')}}\n",
    "$$\n",
    "can be increasingly small as the number of layers $K$ grows, if $\\max{z} a'_\\llp(z) < 1$.\n",
    "\n",
    "Note, for $a_\\llp = \\sigma$ (the sigmoid function), $\\max{z} a'_\\llp(z) = 0.25$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, unless offset by the $f'_\\llp$ terms, $\\loss'_\\llp$ will quickly diminish to $0$ as $K$ decreases,\n",
    "i.e., as we seek to compute $\\loss'_\\llp$ for layers $\\ll$ closest to the input.\n",
    "This means \n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\frac{\\partial \\loss}{\\partial W_\\llp} & = & \\frac{\\partial \\loss}{\\partial y_\\llp} \\frac{\\partial y_\\llp}{\\partial W_\\llp} & = & \\loss'_\\llp \\frac{\\partial y_\\llp}{\\partial W_\\ip}\n",
    "\\end{array}\n",
    "$$\n",
    "will approach $0$.\n",
    "Since this term is used in the update to $W_\\ip$, we won't learn weights for the earliest layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now diagnose one reason that training of early Deep Learning networks was difficult\n",
    "- use of sigmoid activations were common (inspired by biology)\n",
    "- if activations were very large/small, we are in a region where the sigmoid's derivatives are $0$\n",
    "- even when non-zero,the maximum of the derivative of the sigmoid is much smaller than $1$\n",
    "- the end result was that deep networks suffered from Vanishing Gradients\n",
    "\n",
    "The ReLU function's derivative does not suffer from this problem and ReLU's now tend to be\n",
    "the standard activation (barring other considerations, such as the range of outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inside the Training Loop: some code\n",
    "\n",
    "Recall the process of training an $L$ layer (Sequential) Neural Network.\n",
    "\n",
    "A sequence of *epochs* is executed, each epoch involving the processing of each example in the training set.\n",
    "\n",
    "In general, *mini batches* of the training examples divide the epoch into *batches*.\n",
    "\n",
    "(The degenerate case is a single batch consisting of all training examples).\n",
    "\n",
    "Each batch involves two phases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the first phase (called the *Forward Pass*)\n",
    "- Each example $\\x^\\ip, y^\\ip$ is presented as input to the first layer\n",
    "- Compute $\\hat{\\y}^\\ip$ by propagating compuations from layer to layer\n",
    "    - $\\hat{\\y}^\\ip = \\y_L$\n",
    "- Compute the per example loss $\\loss^\\ip_\\W$\n",
    "- The per example losses for the mini batch are summed into a single loss approximation $\\loss_\\W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the second phase (called the *Backward Pass*)\n",
    "- The gradient of the mini batche's loss approximation is computed\n",
    "- $\\W$ is updated, using a learning rate $\\alpha$, in the negative of the direction of the gradient of the loss approximation\n",
    "- Compute the per example gradient of the loss $\\frac{\\partial \\loss^\\ip_\\W}{\\partial \\W}$\n",
    "- The per example gradients of losses for the mini batch are summed into a single gradient loss approximation $\\loss_\\W$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "initialize(W)\n",
    "\n",
    "# Training loop to implement mini-batch SGD\n",
    "for epoch in range(n_epochs):`\n",
    "    for X_batch, y_batch in next_batch(X_train, y_train, batch_size, shuffle=True):\n",
    "        # Forward pass\n",
    "        y = NN(X_batch)\n",
    "        \n",
    "        # Loss calculation\n",
    "        loss = loss_fn(y, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        grads = gradient(loss, W)\n",
    "        \n",
    "        # Update \n",
    "        W = W - grads * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forward API\n",
    "\n",
    "The essential part of the Forward Pass is computing layer $\\\\l$'s output $\\y_\\llp$ from\n",
    "the layer's input $\\y_{(\\ll-1)}$ and the layer's weights $\\W_{(\\ll)}$.\n",
    "\n",
    "$$\n",
    "\\y_{(\\ll)} = a_{(\\ll)}( f_{(\\ll)}( \\y_{(\\ll-1)}, \\W_{(\\ll)})\n",
    "$$\n",
    "\n",
    "For simplicity of presentation, we will temporarily assume that the activation $a_\\llp$ is the identity\n",
    "function.\n",
    "\n",
    "(Without loss of generality, we can implement the activation as a separate layer that also obey's\n",
    "the per layer logic we are about to present)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is some pseudo code to illustrate what happens in the forward and backward passes of back progagaton.\n",
    "\n",
    "It it illustrated with a layer that implements multiplication  $\\y_\\llp = f(x,y) = x * y$.\n",
    "\n",
    "Focus now on the Forward Pass, implemented via the method `forward`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " class MultiplyLayer(Layer):\n",
    "    \"\"\"\n",
    "    A layer that multiplies its two inputs (x,y)\n",
    "    \"\"\"\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        The forward pass: compute the product of x, y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x, y: ndarrays\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        z: ndarray that is the product of x and y\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "        # Compute the product\n",
    "        z = x * y\n",
    "        \n",
    "        # Remember the two inputs: we will need to take derivatives with respect to each\n",
    "        self.x, self.y = x, y\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "   def backward(self, dz): \n",
    "        \"\"\"\n",
    "        The backward pass: \n",
    "        - update the derivative of the loss function (to the derivative wrt the output of the prior layer)\n",
    "        - compute the derivatives of the loss function with respect to each input\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        dz: scalar.  \"loss gradient\": dL/dz: \n",
    "        - The derivative of the loss wrt the output (z) of this layer\n",
    "       \n",
    "        Returns\n",
    "        --------\n",
    "        [dx, dy]: \"local gradients\" wrt inputs [x,y]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "\t# Compute loss gradient of this layer, given that of successor layer\n",
    "\t# Loss gradient this layer = Upstream Loss gradient * local gradient \n",
    "        dL/dx = dL/dz * dz/dx\n",
    "        dL/dy = dL/dz * dz/dt\n",
    "        \n",
    "        Since this layer's operation  is multiplication, z = x*y\n",
    "        - \"local gradients\" are dz/dx = y, dz/dy = x\n",
    "           \n",
    "        dz is given as input\n",
    "        \"\"\"\n",
    "\n",
    "        dx = self.y *dz\n",
    "        dy =  self.x *dz\n",
    "        \n",
    "        return [dx, dy]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can see the essential part of `forward`\n",
    "-  z` = x * y`\n",
    "\n",
    "and that the method returns the result `z`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Backward API\n",
    "\n",
    "In order to update the weights $\\W_\\llp$ we need to compute\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\loss}{\\partial \\W_\\llp}\n",
    "$$\n",
    "\n",
    "\n",
    "During the Backward pass, layer $\\ll$ is given the loss gradient $\\loss'_\\llp$.\n",
    "\n",
    "Via the chain rule we showed\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\frac{\\partial \\loss}{\\partial \\W_\\llp} & = & \\frac{\\partial \\loss}{\\partial \\y_\\llp} \\frac{\\partial \\y_\\llp}{\\partial \\W_\\llp} & = & \\loss'_\\llp \\frac{\\partial \\y_\\llp}{\\partial \\W_\\llp}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "So the key is computing\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\y_\\llp}{\\partial \\W_\\llp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since \n",
    "$$\n",
    "\\y_{(\\ll)} =  f_{(\\ll)}( \\y_{(\\ll-1)}, \\W_{(\\ll)})\n",
    "$$\n",
    "\n",
    "and we know the definition of function $f$ (e.g., multiplication, addition)\n",
    "we can *write the functional form of the derivative* in the Forward Pass.\n",
    "\n",
    "For example:\n",
    "- if $\\y_\\llp = f(x,y) = x * y$ (Multiplication)\n",
    "- We can write\n",
    "    - $\\frac{\\partial \\y_\\llp}{\\partial x} = y$\n",
    "    - $\\frac{\\partial \\y_\\llp}{\\partial y} = x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can see the Backward Pass, implemented by the `backward` method, computes\n",
    "- `dx =  self.y *dz`\n",
    "- `dx` denotes\n",
    "$$\n",
    "\\frac{\\partial \\loss}{\\partial x}\n",
    "$$\n",
    "- The method is given`dz` which denotes\n",
    "$$\n",
    "\\frac{\\partial \\loss}{\\partial \\y_\\llp}\n",
    "$$\n",
    "\n",
    "Since\n",
    "$$\n",
    "\\frac{\\partial \\y_\\llp}{\\partial x}\n",
    "$$\n",
    "equals `y` (which is stored in `self.y`)\n",
    "\n",
    "the chain rule computes `dx` as `self.y * dz`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is a similar forward/backward set of pseudo-code for every operation in the NN\n",
    "- e.g.,\n",
    "addition (of bias $\\b$ to the product $\\W \\x$)\n",
    "- Activation operations (e.g., ReLU, sigmoid).\n",
    "\n",
    "A Deep Learning library is nothing more than a set of similar classes\n",
    "- each implementing a `forward` and `backward`\n",
    "\n",
    "This modular design makes it simple to understand and add to the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning rate schedules\n",
    "\n",
    "In addition to smarter optimzers, we can control learning rates by changing them across epochs of\n",
    "training.\n",
    "\n",
    "This is very much of an art rather than a science.\n",
    "\n",
    "We give a brief overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Warm up\n",
    "[Bag of Tricks for Image Classification using CNNs](https://arxiv.org/abs/1812.01187)\n",
    "\n",
    "- When training starts: initial values of $\\W$ far optimal values\n",
    "- At this point, losses (and gradients) are probably large\n",
    "    - large updates to $\\W$ might cause instability\n",
    "\n",
    "So, we can start off \"slow\" with a low initial rate during a *warm-up period*.\n",
    "- low learning rate compensates for high gradient\n",
    "\n",
    "Post the warm-up, we can use a higher rate to speed training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Post warm-up\n",
    "\n",
    "Typical strategy has been to decrease learning rate as the number of epochs increase.\n",
    "\n",
    "Idea is to take smaller steps as we approach the region of optimality\n",
    "- don't want to overshoot\n",
    "\n",
    "There are many ways to set a learning rate schedule (a function that maps epoch number to a rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- step schedule\n",
    "    - vary rate by epoch\n",
    "    - rate decreases as epoch increases\n",
    "- cosine decay\n",
    "    - decrease rate according to a cosine function\n",
    "        - $\\text{learning_rate}_{t} = {1\\over{2}} \\left( 1 + \\cos(  \\pi{{t}\\over{T}} ) \\right)  * \\text{learning_rate}_{0} $\n",
    "            - where $\\text{learning_rate}_{0}$ is initial learning rate, $T$ is number of batches\n",
    "        - slow decrease in rate at start\n",
    "        - near-linear decrease in middle\n",
    "        - slow decrease near end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_= nnh.plot_cosine_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What took so long ?\n",
    "\n",
    "We had briefly discussed this topic in a prior lecture.\n",
    "We will now dive more deeply into the multitude of reasons for why it took so long for \n",
    "Deep Learning to achieve success.\n",
    "\n",
    "An historical perspective:\n",
    "\n",
    "- Perceptron invented 1957\n",
    "- mid-1970's: First \"AI Winter\"\n",
    "- Late 1980's: secibd \"AI Winter\"\n",
    "- 2010: Re-emergence of AI\n",
    "\n",
    "The promise of AI led to great expectations, that were ultimately unfulfilled.\n",
    "The difficulty was the inability to train networks.\n",
    "\n",
    "We now spend some time investigating the causes, and solutions, to the difficulty of training networks.\n",
    "\n",
    "Broadly speaking the issues are\n",
    "- proper scaling of the inputs\n",
    "- initialization of learnable weights\n",
    "- making sure that the proper scaling of inputs continues to each layer, not just the input\n",
    "\n",
    "-\n",
    "**TO DO**\n",
    "Not a great transition.\n",
    "- particularly arguing the need for zero-centered, unit variance: was known for a while\n",
    "- Find a better way to introduce the following sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Proper scaling of inputs\n",
    "\n",
    "## Importance of zero centered inputs (for each layer)\n",
    "[Efficient Backprop paper, LeCunn98](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n",
    "\n",
    "**Zero centered** means average (over the training set) value of each feature of examples is mean $0$.\n",
    "\n",
    "Gradient descent updates each element of a layer $\\ll$'s weights $\\W_\\llp$ by\n",
    "the per-example losses \n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\frac{\\partial \\loss^\\ip }{\\partial W_\\llp} & = & \\frac{\\partial \\loss^\\ip}{\\partial \\y_\\llp^\\ip} \\frac{\\partial \\y_\\llp^\\ip}{\\partial \\W_\\llp} \n",
    "\\end{array}\n",
    "$$\n",
    "summed over examples $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Over-simplifying:\n",
    "- the local derivative is proportional to the input:\n",
    "$$\n",
    "\\frac{ \\partial{\\y_\\llp^\\ip} } { \\partial \\W_\\llp } = a'_\\llp \\y_{(\\ll-1)}^\\ip\n",
    "$$\n",
    "for FC $y_\\llp = a_\\llp ( \\y_{(\\ll-1)} \\W_\\llp )$.\n",
    "- thus the updates of $\\W_{\\llp,j}$ will be biased by $\\bar{\\y}_{(\\ll-1),j}$ = the average (over examples $i$) of $\\y_{(\\ll-1),j}^\\ip$\n",
    "- for $\\ll = 1$, this is the average of the input feature $\\x_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the particular case that each feature $j$'s average $\\bar{\\x}_j$ has the same sign:\n",
    "- updates in all dimensions will have the same sign\n",
    "- this can result in an indirect \"zig-zag\" toward the optimum\n",
    "    - Exampe: two dimensions: \n",
    "        - We can navigate the loss surface north-east or south-west only ! \n",
    "        - To get to a point north-west from the current, we have to zig-zag.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Note that this is an issue for *all* layers, not just layer $\\ll =1$.\n",
    "\n",
    "- Also note: the problem is compounded by activations whose outputs are not zero-centered (e.g., ReLU, sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importance of unit variance inputs (weight initialization)\n",
    "\n",
    "The same argument we made for zero-centering a feature can be extended to it's variance:\n",
    "- the variance of feature $j$ over all trainng examples $i$ is the varaince of $\\y_{(\\ll-1),j}$\n",
    "\n",
    "If the variance of features $j$ and $j'$ are different, their updates will happen at different rates.\n",
    "\n",
    "We will examine this in greater depth during our discussion of weight initialization.\n",
    "\n",
    "For now: it is desirable that the input to *each* layer have it's features somewhat normalized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Initialization\n",
    "\n",
    "Training is all about discovering good weights.\n",
    "\n",
    "As prosaic as it sounds: how do we *initialize* the weights before training ?\n",
    "Does it matter ?\n",
    "\n",
    "It turns out that the choice of initial weights does matter.\n",
    "\n",
    "Let's start with some *bad* choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bad choices\n",
    "\n",
    "### Too big/small\n",
    "\n",
    "Layers usually consist of linear operations (e.g., matrix multiplication and addition of bias)\n",
    "followed by a non-linear activation.\n",
    "The range of many activation functions includes large regions where the derivatives are near zero,\n",
    "usually corresponding to very large/small activations.\n",
    "\n",
    "The SGD update rule uses the magnitude of the gradient to update weights.\n",
    "Obviously, if the gradients are all near-0, learning cannot occur.\n",
    "\n",
    "So one bad choice is any set of weights that tends to push activations to regions of the non-linear\n",
    "activation with zero gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Identical weights\n",
    "\n",
    "Consider layer $\\ll$ with $n_\\ll$ units (neurons) implementing identical operations (e.g. FC + ReLu).\n",
    "\n",
    "Let  $\\W_{\\llp, k}$ denote the weights of unit $k$.\n",
    "\n",
    "Suppose we initialized the weights (and biases) of all units to the *same* vector.\n",
    "$$\n",
    "\\W_{\\llp, k} = \\w_\\llp, \\; 1 \\le k \\le n_\\ll\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider two neuron $j, j'$ in the same layer $\\ll$\n",
    "$$\n",
    "\\begin{array}[lll]\\\\\n",
    "\\y_{\\llp, j}  & = & a_\\llp ( \\w_\\llp \\y_{(\\ll-1)} + \\b_\\llp ) \\\\\n",
    "\\y_{\\llp, j'} & = & a_\\llp ( \\w_\\llp \\y_{(\\ll-1)} + \\b_\\llp ) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- Both neuron will compute the same activation\n",
    "- Both neurons will have the same gradient\n",
    "- Both neurons will have the same weight update\n",
    " \n",
    "Thus, the weights in layer $i$ will start off identical and will remain identical due to identical updates.\n",
    "\n",
    "So identical initialization will lead to a failure for individual neurons to learn different features.\n",
    "\n",
    "Many approaches use some for of random initialization to break the symmetry we just described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Glorot initialization\n",
    "\n",
    "We have previousy shown that each element $j$ of the first input layer ($\\x_{(0),j}$) should\n",
    "have unit variance across the training set.  \n",
    "\n",
    "This was meant to ensure that the first layer's weights\n",
    "updated at the same rate and that the activations of the first layer fell into regions of the activation\n",
    "function that had non-zero gradients.\n",
    "\n",
    "But this is not enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's assume for the moment that each element $j$ of the input vector $\\y_{(\\ll-1)}$ is mean $0$, unit variance\n",
    "and mutually independent.  \n",
    "\n",
    "So view each $\\y_{(\\ll-1),j}$ as an independent random variable with mean $0$\n",
    "and unit variance.  Furthermore, let's assome each element $\\W_{\\llp,j}$ is similarly distributed.\n",
    "\n",
    "Consider the matrix multiplication in layer $\\ll$ involving the $n_{\\ll-1}$ output of layer $\\ll$.\n",
    "$$f_\\llp(\\y_{(\\ll-1)}, W_\\llp) = \\y_{(\\ll-1)} \\cdot W_\\llp$$\n",
    "\n",
    "This expression is the weighted sum over $j$ of the product of\n",
    "- a mean 0, unit variance random variable $\\y_{(\\ll-1),j}$\n",
    "- a mean 0, unit variancerandom variable  $\\W_{\\llp,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For two random variables $X, Y$, the variance of the product \n",
    "[is](https://en.wikipedia.org/wiki/Variance#Product_of_independent_variables)\n",
    "\n",
    "$$\n",
    "\\text{Var}(XY) = \\mathbb{E}(X)^2 \\text{Var}(Y) + \\mathbb{E}(Y)^2 \\text{Var}(X) + \\text{Var}(X)\\text{Var}(Y)\n",
    "$$\n",
    "\n",
    "So \n",
    "$$\\text{Var}(\\y_{(\\ll-1),j} \\W_{\\llp,j}) = 0^2 * 1 + 0^2 * 1 + 1 * 1 = 1\n",
    "$$\n",
    "\n",
    "Thus the variance of the dot product of $n_{\\ll-1}$ products is $n_{\\ll-1}$, not $1$ as desired.\n",
    "\n",
    "However, by scaling each $\\W_{\\llp,j}$ by \n",
    "$$\n",
    "\\frac{1}{\\sqrt{n_{\\ll-1}}}\n",
    "$$\n",
    "the variance becomes $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Glorot* (also called *Xavier*) initialization sets the initial weights to a number drawn from \n",
    "mean $0$, unit variance distribution (either normal or uniform)\n",
    "$\\frac{1}{\\sqrt{n_{\\ll-1}}}\n",
    "$.\n",
    "\n",
    "Note that we don't strictly need the requirement of unit variance -- it works equally well as long\n",
    "as the input and output variances are the same, which is the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This only partially solves the problem as it only ensures unit variance of the input to the activation function.\n",
    "\n",
    "The [original Glorot paper](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) justifies this\n",
    "by assuming either a $\\tanh$ or sigmoid activation functions and these functions can be approximated\n",
    "as linear in the active region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus far, we have achieved unit variance during the forward pass.\n",
    "During back propagation, it was shown that the scaling factor depends on the number of outputs\n",
    "of layer $\\ll$, rather than number of inputs, so the scaling factor needs to be\n",
    "$\\frac{1}{\\sqrt{n_\\ll}}\n",
    "$\n",
    "\n",
    "Taking the average of the two scaling factors gives a final factor of\n",
    "$\\frac{1}{\\sqrt{ \\frac{ n_{\\ll-1} + n_\\ll}{2} } } = \\sqrt{\\frac{2}{n_{\\ll-1} + n_\\ll}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kaiming/He initialization\n",
    "\n",
    "[Kaiming et al](https://arxiv.org/pdf/1502.01852.pdf) extended the results of Glorot et. al\n",
    "to the ReLU activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The ReLU activation has two distinct regions: one linear (for inputs greater than 0) and one all zero.\n",
    "\n",
    "The linear region of the activation corresponds to the assumption of the Glorot method.\n",
    "\n",
    "So if inputs to the ReLU are equally distributed around 0, this is approximately the same\n",
    "as the Glorot method with half the number of inputs.\n",
    "- that is: half of the ReLU's will be in the active region and half will be in the inactive region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Kaiming scaling factor is thus:\n",
    "$$\n",
    "\\sqrt{\\frac{2}{n_{(\\ll-1)}} }\n",
    "$$\n",
    "in order to preserve unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Layer-wise pre-training\n",
    "\n",
    "We discussed this in the Autoencoder lecture.\n",
    "\n",
    "In the absence of a \"good\" idea for initializing layer $\\ll$'s weights\n",
    "- train layer $\\ll$ as an Autoencdoer\n",
    "    - train it so that input $y_{(\\ll-1)}$ has target $y_{(\\ll-1)}$ \n",
    "    - this will result in weights $\\W_\\llp$ that have discovered some structure among the features $y_{(\\ll-1)}$\n",
    "    - Initialize the weights of layer $\\ll$ to the ones produced by the Autoencoder\n",
    "- These weights *may or may not* be useful in predicting $\\hat{\\y} = \\y_{(L)}$\n",
    "- But they are probably better than random weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization\n",
    "\n",
    "- We addressed the importance of normalization of the inputs to layer $\\ll = 1$.\n",
    "- The same argument applies to *all* layers $\\ll > 0$\n",
    "\n",
    "We discuss some Normalization methods that attempt to keep the distribution of $\\y_{\\llp,j}$\n",
    "normalized through all layers $\\ll$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Batch normalization\n",
    "[Batch Normalization paper](https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "The idea behind batch normalization:\n",
    "-  perform standardization  (mean $0$, standard deviation 1)\n",
    "at each layer, using the mean and standard deviation of each minibatch.\n",
    "\n",
    "- faciliates higher learning rate \n",
    "    - controlling the size of the derivative allows higher $\\alpha$ without increasing product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Experimental results show that the technqiue:\n",
    "- facilitates the use of much higher learning rates, thus speeding training.  Accuracy is not lost.\n",
    "- facilitates the use of saturating activations functions (e.g., $\\tanh$ and sigmoid) which otherwise are subject to vanishing/exploding gradients.\n",
    "- acts as a regularizer; reduces the need for Dropout\n",
    "    - L2 regularization (weight decay) has *no* regularizing effect when used with Batch Normalization !\n",
    "        - [see](https://arxiv.org/abs/1706.05350)\n",
    "        - L2 regularization affects scale of weights, and thereby learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Details\n",
    "\n",
    "Consider a FC layer $\\ll$ with $n_\\ll$ outputs and a mini-batch of size $m_B$.\n",
    "\n",
    "Each of the $n_\\ll$ outputs is the result of\n",
    "- passing a linear combination of $\\y_{(\\ll -1)}$ (*activation inputs*)\n",
    "-  through an activation $a_{\\llp,j}$ (*activation outputs*)\n",
    "\n",
    "We could choose to standardize either the activation inputs or the activation outputs.\n",
    "\n",
    "This algorithm standardizes the **activation inputs**.\n",
    "\n",
    "Standardization is performed relative to the mean and standard deviation of each batch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Summary for layer $\\ll$ with equation $\\y_\\llp = a_\\llp( \\W_\\llp \\y_{(\\ll-1)})$\n",
    "- each output feature $j$: $\\y_{\\llp,j} = a_{\\llp,j}( \\W_{\\llp,j} \\y_{(\\ll-1)})$\n",
    "\n",
    "- Denote the dot product for output feature $j$ by $\\x_{\\llp,j} = \\W_{\\llp,} \\y_{(\\ll-1)}$\n",
    "- We will replace $\\x_{\\llp,j}$ by a \"standardized\" $\\z_{\\llp,j}$ to be described\n",
    "\n",
    "Rather than carrying along supscript $j$\n",
    "we write all operations on  the collection $\\x_{\\llp,j}$ as a vector operation on $\\x_\\llp$ for ease of notation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$\n",
    "\\begin{split}\n",
    "1.\\quad & \\mathbf{\\mu}_B = \\dfrac{1}{m_B}\\sum\\limits_{i=1}^{m_B}{\\mathbf{x}^{(i)}}\\\\\n",
    "2.\\quad & {\\mathbf{\\sigma}_B}^2 = \\dfrac{1}{m_B}\\sum\\limits_{i=1}^{m_B}{(\\mathbf{x}^{(i)} - \\mathbf{\\mu}_B)^2}\\\\\n",
    "3.\\quad & \\hat{\\mathbf{x}}^{(i)} = \\dfrac{\\mathbf{x}^{(i)} - \\mathbf{\\mu}_B}{\\sqrt{{\\mathbf{\\sigma}_B}^2 + \\epsilon}}\\\\\n",
    "4.\\quad & \\mathbf{z}^{(i)} = \\gamma \\hat{\\mathbf{x}}^{(i)} + \\beta\n",
    "\\end{split}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So\n",
    "- $\\mathbf{\\mu}_B, \\mathbf{\\sigma}_B$ are vectors (of length $n_\\ll$) of \n",
    "    - the element-wise means and standard deviations (computed across the batch of $m_B$ examples)\n",
    "- $\\mathbf{\\hat{x}^{(i)}}$ is standardized $\\mathbf{x}^{(i)}$ \n",
    "\n",
    "** Note the $\\epsilon$ in the denominator is their solely to prevent \"divide by 0\" errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is going on with $\\z^\\ip$ ?  \n",
    "\n",
    "Why are we constructing it with mean $\\beta$ and standard deviation $\\gamma$ ?\n",
    "\n",
    "$\\beta, \\gamma$ which are **learned** parameters.\n",
    "\n",
    "Why should $\\beta, \\gamma$ be learned ?\n",
    "\n",
    "At a minimum: it can't hurt:\n",
    "- it admits the possibility of the identity transformation\n",
    "    - which would be the simple standardization\n",
    "- but allows the unit to be non-linear when there is a benefit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moreover, depending on the activation $a_{\\llp, j}$\n",
    "- $\\hat{\\x}_{\\llp,j}$ can wind up *within the active region* of the activation function\n",
    "\n",
    "This effectively makes our transformations linear, rather than non-linear, which are more powerful.\n",
    "\n",
    "By shifting the mean by $\\beta$ we gain the *option* to avoid this should it be beneficial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The final question is: what do we do at inference/test time, when all \"batches\" are of size 1 ?\n",
    "\n",
    "The answer is\n",
    "- compute a single $\\mathbf{\\mu}, \\mathbf{\\sigma}$ from the sequence of such values across all batches.\n",
    "- \"population\" statistics (over full training set\n",
    "- rather than \"sample\" statistics (from a single training batch).\n",
    "\n",
    "Typically a moving average is used.\n",
    "We refer readers to the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We create a new layer type $\\text{BN}$ to perform Batch Normalization to the inputs of any layer.\n",
    "\n",
    "Thus, it particpates in both the forward (i.e., normalization) and backward (gradient computation)\n",
    "steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unbelievably good initialization\n",
    "\n",
    "Glorot and Kaiming weight initialization \n",
    "- ensures \"good\" distribution of outputs of a layer, given a good distribution of inputs to the layer\n",
    "\n",
    "Normalization (e.g., Batch Normalization)\n",
    "- tries to ensure good distribution of inputs across al layers\n",
    "\n",
    "There are some initialization methods that attempt to create weights that are so good,\n",
    "that Normalization during training is no longer necessary.\n",
    "\n",
    "[Fixup initialization paper](https://arxiv.org/abs/1901.09321)\n",
    "- good initialization means you don't need normalization layers\n",
    "\n",
    "But good initialization can help too.\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How big should my NN be ?\n",
    "\n",
    "There is a paradox in building Neural Networks:\n",
    "- Start off training an overly large NN (many units)\n",
    "- Many units turn out to be \"dead\": near zero weights\n",
    "- Reduce the number of units\n",
    "- Can't train !\n",
    "\n",
    "Given a fixed number of layers: it is easier to train a big NN than a small one.\n",
    "\n",
    "\"Somewhere in this big mess must be something valuable\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>\"Big\" NN with dead nodes</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=images/Dropout_NN_wo_dropout.jpg width=400></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>\"Big\" NN after dead nodes have been pruned</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=images/Dropout_NN_w_dropout.jpg width=400></td>\n",
    "    </tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635)\n",
    "is an interesting paper that addresses this issue.\n",
    "\n",
    "For now:\n",
    "- Use bigger than necessary NN's\n",
    "- With regularization to \"prune\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization\n",
    "\n",
    "The ultimate goal of Machine Learning is out of sample prediction.\n",
    "\n",
    "Because Neural Networks often learn a large number of parameters (weights), overfitting is a concern.\n",
    "\n",
    "We will briefly review several methods to combat overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cost function: add regularization penalty\n",
    "\n",
    "The same methods that were applicable in Classical Machine Learning apply to Deep Learning as well.\n",
    "\n",
    "These include regularization penalties that aim to reduce the number of parameters.\n",
    "- L2 regularization\n",
    "- L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dropout\n",
    "\n",
    "[Droput paper](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
    "\n",
    "Overfitting can occur because some weights in the NN adapt so as to memorize \"noisy\" features.\n",
    "\n",
    "*Dropout* is a method that *randomly drops a unit in the NN*\n",
    "- For each training example $\\x^\\ip$\n",
    "- Each unit gets dropped with probability $p$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>NN, no dropout</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=images/Dropout_NN_wo_dropout.jpg width=400></td>\n",
    "    </tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>NN, 50% dropout</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=images/Dropout_NN_w_dropout.jpg width=400></td>\n",
    "    </tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Neural Network with $N$ units contains $2^N$ possible sub-networks.\n",
    "\n",
    "Dropout can be viewed as training many of these sub-networks (with weights shared by sub-networks.)\n",
    "\n",
    "If a feature is truly important, the NN must adapt to robustly recognize the feature.\n",
    "\n",
    "If it is not important, the goal is to prevent a unit from memorizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In Keras, Dropout is implemented by a layer:\n",
    "\n",
    "`Dropout(rate)`\n",
    "\n",
    "where `rate` is the probability of dropping a unit.\n",
    "\n",
    "Dropout has been supplanted by Batch Normalization, but is worth studying \n",
    "- for its simplicity and ease of use\n",
    "- inspiration it offers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Augmentation \n",
    "\n",
    "It is sometimes possible to expand the training set in such a way as to discourage overfitting.\n",
    "\n",
    "This usually involves \n",
    "creating variants of training examples\n",
    "- make it hard to memorize them all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Input Transformation\n",
    "\n",
    "Alter the image while preserving its label.\n",
    "\n",
    "- Image transformation\n",
    "    - rotate, crop, flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Label smoothing\" reducing prediction confidence\n",
    "\n",
    "[Label Smoothing paper](https://arxiv.org/pdf/1701.06548.pdf)\n",
    "\n",
    "Recall our discussion about the difference between Cross Entropy and Hinge Loss\n",
    "- Hinge Loss \"stops trying\" to improve parameters when they are just \"good enough\" to yield a correct prediction\n",
    "- Cross Entropy: tries to improve probablity to exactly $0$ or $1$\n",
    "\n",
    "Cross Entropy's relentless search for improvement may lead to poor out of sample generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A class of solutions exists to discourage the NN from seeking absolute confidence in its prediction.\n",
    "\n",
    "*Label Smoothing* changes binary targets to values that are only approximately $0$ or $1$.\n",
    "\n",
    "| Example | Smoothed label\n",
    "| :- | -----\n",
    "| $(\\x^\\ip, 0)$ | $(\\x^\\ip, 0 + \\epsilon)$\n",
    "| $(\\x^\\ip, 1)$ | $(\\x^\\ip, 1 - \\epsilon)$\n",
    "\n",
    "\n",
    "So rather than using One Hot Encoding (OHE), we use \"$\\epsilon$ Hot Encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mixup training\n",
    "[Mixup training paper](https://arxiv.org/abs/1905.11001)\n",
    "\n",
    "*Mixup training* is a second solution to prevent an NN from seeking absolute confidence.\n",
    "\n",
    "It creates additional training examples that are *mixtures* of existing examples:\n",
    "\n",
    "\n",
    "| &nbsp; &nbsp; &nbsp; &nbsp; Training example &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;         | Mixup ? \n",
    "|:--- | :--- \n",
    "| $(\\x^\\ip, \\y^\\ip)$ &nbsp; &nbsp; &nbsp;  &nbsp; | original\n",
    "| $(\\x^{(i')}, \\y^{(i')})$ &nbsp; &nbsp; &nbsp; | original\n",
    "| $(\\x^\\ip + \\lambda \\x^{(i')}, \\y^\\ip) + \\lambda \\y^{(i')})$ | Mixup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The mixing parameter $\\lambda$ is best when it is close to $0$ or $1$\n",
    "- $(0 + \\epsilon)$ or $(1 - \\epsilon)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.547px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
